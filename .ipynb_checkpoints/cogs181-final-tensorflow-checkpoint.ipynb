{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O0q097e_b5Uy"
   },
   "source": [
    "### Note\n",
    "\n",
    "This notebook is the first attempt at CNN using tensorflow for experiment only. \n",
    "\n",
    "Major work and result is preduced using keras in the other notebook: **cogs181-final-project(keras).ipynb**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8aghMOeKbo11"
   },
   "source": [
    "# Setup, Download and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 170,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2555,
     "status": "ok",
     "timestamp": 1513036568083,
     "user": {
      "displayName": "Tony Lim",
      "photoUrl": "//lh3.googleusercontent.com/-DO9616bnct4/AAAAAAAAAAI/AAAAAAAADOc/rjhjTHF-kxU/s50-c-k-no/photo.jpg",
      "userId": "100029816334508670274"
     },
     "user_tz": 480
    },
    "id": "0pSng7KtuSoW",
    "outputId": "d0ba9a0f-5fd5-4339-b2a1-1be674c193f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow-gpu\r\n",
      "Version: 1.4.0.dev20171012\r\n",
      "Summary: TensorFlow helps the tensors flow\r\n",
      "Home-page: https://www.tensorflow.org/\r\n",
      "Author: Google Inc.\r\n",
      "Author-email: opensource@google.com\r\n",
      "License: Apache 2.0\r\n",
      "Location: /opt/conda/lib/python2.7/site-packages\r\n",
      "Requires: enum34, backports.weakref, wheel, mock, tensorflow-tensorboard, numpy, protobuf, six\r\n"
     ]
    }
   ],
   "source": [
    "# To determine which version you're using:\n",
    "!pip show tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "  \n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g7fRT5eTuVQr"
   },
   "outputs": [],
   "source": [
    "!cd /tmp; wget --quiet http://pages.ucsd.edu/~ztu/courses/tiny-imagenet-200.zip\n",
    "!cd /tmp; unzip -qq tiny-imagenet-200.zip; rm tiny-imagenet-200.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_32fTulcA9_"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VkBIPDH_4yPi"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import scipy.ndimage\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from tensorflow.contrib.learn.python.learn.datasets.mnist import DataSet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "def distort(filename):\n",
    "    \"\"\"Apply image distortions\"\"\"\n",
    "    with tf.Graph().as_default():\n",
    "        file = tf.read_file(filename)\n",
    "        img = tf.image.decode_jpeg(file, 3)\n",
    "        img = tf.image.adjust_saturation(img, 0.5)\n",
    "        img = tf.image.adjust_hue(img, -0.05)\n",
    "        with tf.Session() as sess:\n",
    "            dist_img = sess.run(img)\n",
    "    \n",
    "    return dist_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGQ2FlzicDuN"
   },
   "source": [
    "### Data Exploratory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "p9nGkMtpsCFs"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "path = \"/tmp/tiny-imagenet-200/\"\n",
    "train_dirs = glob.glob(path + \"train/*\")\n",
    "val_dirs   = glob.glob(path + \"val/*\")\n",
    "test_dirs  = glob.glob(path + \"test/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5DfQNHZk3KoZ"
   },
   "source": [
    "#### Loading All Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34,
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1513051145558,
     "user": {
      "displayName": "Tony Lim",
      "photoUrl": "//lh3.googleusercontent.com/-DO9616bnct4/AAAAAAAAAAI/AAAAAAAADOc/rjhjTHF-kxU/s50-c-k-no/photo.jpg",
      "userId": "100029816334508670274"
     },
     "user_tz": 480
    },
    "id": "KqGZvL1mvGpx",
    "outputId": "a7f7d4e0-c1a3-4a38-be47-dff3b6eb1148"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is global labels, there are 18K of them, but only 200 is used for training and validation\n",
    "labels = []\n",
    "for line in open(path + 'words.txt'):\n",
    "    [classname, description ] = line.strip().split('\\t')\n",
    "    labels.append( (classname,description) )\n",
    "label_dicts = dict(labels)\n",
    "\n",
    "# There are only 200 used labels in both training and validation\n",
    "used_labels =  [ d[-9:] for d in train_dirs ]\n",
    "len(used_labels)\n",
    "\n",
    "# Hot-Encode Labels\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "bin_encoder = LabelBinarizer()\n",
    "bin_encoder.fit_transform(used_labels).size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wjOwALs23NdV"
   },
   "source": [
    "#### Loading Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_paths = []\n",
    "train_labels = []\n",
    "for class_path in train_dirs:\n",
    "    class_name = class_path[-9:]\n",
    "    images = glob.glob(class_path + '/images/*')\n",
    "    for image_path in images:\n",
    "        train_labels.append( class_name )\n",
    "        train_data_paths.append( image_path )\n",
    "        \n",
    "inter = list(zip(train_data_paths, train_labels))\n",
    "random.shuffle(inter)\n",
    "train_data_paths, train_labels = zip(*inter)\n",
    "\n",
    "train_labels = bin_encoder.transform(train_labels) # hot-encode labels from string to number\n",
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(img_path):\n",
    "    img = scipy.ndimage.imread(img_path)\n",
    "    if len(img.shape) != 3: # reshape back to RBG format\n",
    "        img = np.repeat(img[:,:,np.newaxis], 3, axis=2)\n",
    "    return img\n",
    "\n",
    "def get_images(paths):\n",
    "    X = []\n",
    "    for p in paths:\n",
    "        X.append(get_image(p))\n",
    "    return X\n",
    "        \n",
    "def prepare_batch(X,y,batch_size=50):\n",
    "    N = len(y) / batch_size\n",
    "    i = 0\n",
    "    yield X[:batch_size], y[:batch_size]\n",
    "    while i < N:\n",
    "        yield X[batch_size*i:batch_size*(i+1)], y[batch_size*i:batch_size*(i+1)]\n",
    "        i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Fw4XvvF525O2"
   },
   "outputs": [],
   "source": [
    "# inter = list(zip(train_images, train_labels))\n",
    "# random.shuffle(inter)\n",
    "# images, labels = zip(*inter)\n",
    "# train_data = DataSet( np.array(train_images), np.array(train_labels), reshape=False)\n",
    "# del train_images, train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4DBoIC9ED9w"
   },
   "source": [
    "### Loading Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "d9tihkh-B5oP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels = []\n",
    "val_fns = []\n",
    "val_images = []\n",
    "for line in open(path + 'val/val_annotations.txt'):\n",
    "  [fn, classname, _ , _, _, _ ] = line.strip().split('\\t')\n",
    "  \n",
    "  img = scipy.ndimage.imread(path +'val/images/' + fn )\n",
    "  if len(img.shape) != 3: # reshape back to RBG format\n",
    "      img = np.repeat(img[:,:,np.newaxis], 3, axis=2)\n",
    "      \n",
    "  val_labels.append(classname)\n",
    "  val_images.append(img)\n",
    "\n",
    "# hot-encode labels from string to number\n",
    "# val_labels = encoder.transform(val_labels)\n",
    "val_labels = bin_encoder.transform(val_labels)\n",
    "\n",
    "val_data = DataSet( np.array(val_images), np.array(val_labels), reshape=False)\n",
    "del val_labels, val_images\n",
    "val_data.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 64, 64, 3), (2000, 200))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mini-validation set\n",
    "_x_val, _y_val = val_data.next_batch(2000)\n",
    "_x_val.shape, _y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kfAEt-8zcFxL"
   },
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "_RY9ds0NEocN"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Network Parameters\n",
    "n_classes = 200\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pooling2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 64, 64, 3], name='x')\n",
    "Y = tf.placeholder(\"float\", [None, n_classes], name='y_true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "fM9Fy2IZEVti"
   },
   "outputs": [],
   "source": [
    "class ConvNet():\n",
    "    \n",
    "    def __init__(self, conv_fn, pooling_fn, activation_fn):\n",
    "        self._conv_fn = conv_fn\n",
    "        self._pooling_fn = pooling_fn\n",
    "        self._activation_fn = activation_fn\n",
    "    \n",
    "    def conv_layer(self, x, n_filters, kernel_size):\n",
    "        shape = [kernel_size] * 2\n",
    "        shape = shape + [x.shape[-1].value, n_filters]\n",
    "        \n",
    "        w = weight_variable(shape)\n",
    "        b = bias_variable([n_filters])\n",
    "        return self._activation_fn(self._conv_fn(x, w) + b)\n",
    "    \n",
    "    def pool_layer(self, x, n_strides, kernel_size):\n",
    "        return self._pooling_fn(x)\n",
    "    \n",
    "    def fc_layer(self, x, n_neurons):\n",
    "        mult = lambda x, y: x * y\n",
    "        \n",
    "        shape = x.get_shape().as_list()[1:]\n",
    "        flat_shape = reduce(mult, shape, 1)\n",
    "        \n",
    "        w = weight_variable([flat_shape, n_neurons])\n",
    "        b = bias_variable([n_neurons])\n",
    "        x_flat = tf.reshape(x, [-1, flat_shape])\n",
    "        fc = self._activation_fn(tf.matmul(x_flat, w) + b)\n",
    "        return fc\n",
    "    \n",
    "    def out_layer(self, x, n_classes):\n",
    "        w = weight_variable([x.shape[-1].value, n_classes])\n",
    "        b = bias_variable([n_classes])\n",
    "        return tf.matmul(x, w) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GoiaIrfs2FRx"
   },
   "source": [
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/datasets/mnist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "8FQJfHYt2GEx"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "# Convolutions use a stride of one\n",
    "# Plain old max pooling over 2x2 blocks\n",
    "# Activation function is the ReLu function\n",
    "conv_net = ConvNet(conv2d, max_pooling2d, tf.nn.relu)\n",
    "\n",
    "# Reshape to match picture format [Height x Width x Channel]\n",
    "x_image = tf.reshape(X, [-1, 64, 64, 3], name='X')\n",
    "\n",
    "# Convolution Layer with 32 filters and a kernel size of 5\n",
    "conv1 = conv_net.conv_layer(x_image, 32, 5)\n",
    "\n",
    "# Convolution Layer with 64 filters and a kernel size of 5\n",
    "conv2 = conv_net.conv_layer(conv1, 64, 5)\n",
    "\n",
    "# Fully connected layer with 1024 neurons\n",
    "fc = conv_net.fc_layer(conv2, 1024)\n",
    "\n",
    "# Applying a dropout before the readout layer to reduce\n",
    "# overfitting\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "fc = tf.nn.dropout(fc, keep_prob)\n",
    "\n",
    "# Readout layer\n",
    "y_conv = conv_net.out_layer(fc, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 286,
     "output_extras": [
      {
       "item_id": 5
      },
      {
       "item_id": 6
      }
     ]
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 584814,
     "status": "error",
     "timestamp": 1513051779388,
     "user": {
      "displayName": "Tony Lim",
      "photoUrl": "//lh3.googleusercontent.com/-DO9616bnct4/AAAAAAAAAAI/AAAAAAAADOc/rjhjTHF-kxU/s50-c-k-no/photo.jpg",
      "userId": "100029816334508670274"
     },
     "user_tz": 480
    },
    "id": "HB0giFqzGEky",
    "outputId": "7817e3fd-b298-4dc9-f431-664e2140ccfb"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits=y_conv, labels=Y))\n",
    "optimizer     = tf.train.AdamOptimizer(learning_rate)\n",
    "train_step    = optimizer.minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(Y, 1))\n",
    "accuracy           = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "\n",
    "train_loss,train_acc  = [],[]\n",
    "val_acc   , test_acc  = [],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 2000, training accuracy 0\n",
      "step 4000, training accuracy 0\n",
      "step 6000, training accuracy 0\n",
      "step 8000, training accuracy 0\n",
      "step 10000, training accuracy 0\n",
      "step 12000, training accuracy 0\n",
      "step 14000, training accuracy 0\n",
      "step 16000, training accuracy 0\n",
      "step 18000, training accuracy 0\n",
      "step 20000, training accuracy 0\n",
      "step 22000, training accuracy 0\n",
      "step 24000, training accuracy 0\n",
      "step 26000, training accuracy 0\n",
      "step 28000, training accuracy 0\n"
     ]
    }
   ],
   "source": [
    "# Training Parameters\n",
    "epoch = 15             # two pass on all training_data\n",
    "batch_size = 25        # in each iteration, train 50, total iteration = 100K / batch_size (in the case of 25 batch size, 4K iteration)\n",
    "\n",
    "# Use interactive session instead\n",
    "# with tf.Session() as sess:\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "i = 0\n",
    "for e in range(epoch):\n",
    "    for img_paths, batch_y in prepare_batch(train_data_paths, train_labels, batch_size=batch_size):\n",
    "        batch_x = get_images(img_paths)\n",
    "        _, loss = sess.run([train_step, cross_entropy], feed_dict={X: batch_x, Y: batch_y, keep_prob: 0.5})\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={X: batch_x, Y: batch_y, keep_prob: 1.0})\n",
    "        train_acc.append(train_accuracy)\n",
    "        train_loss.append(loss)\n",
    "        i += 1\n",
    "        if i % 2000 == 0:\n",
    "            print('step %d, training accuracy %g' % (i, train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy 0.025\n",
      "val accuracy 0.025\n",
      "val accuracy 0.032\n",
      "val accuracy 0.031\n",
      "val accuracy 0.022\n",
      "val accuracy 0.033\n",
      "val accuracy 0.021\n",
      "val accuracy 0.025\n",
      "val accuracy 0.018\n",
      "val accuracy 0.027\n"
     ]
    }
   ],
   "source": [
    "print('val accuracy %g' % accuracy.eval(session=sess, feed_dict={ X: val_data.images[:1000], Y: val_data.labels[:1000], keep_prob: 1.0}))\n",
    "for i in range(9):\n",
    "    print('val accuracy %g' % accuracy.eval(session=sess, feed_dict={ X: val_data.images[ i*1000 : (i+1)*1000 ], Y: val_data.labels[ i*1000:(i+1)*1000], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "COGS181-Final.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
